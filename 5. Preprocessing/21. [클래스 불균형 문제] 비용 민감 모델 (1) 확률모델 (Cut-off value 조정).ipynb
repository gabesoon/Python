{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비용 민감 모델\n",
    "---\n",
    "- 위음성 비용과 위양성 비용을 다르게 설정하는 모델\n",
    "- 즉, `위음성 비용 = w x 위양성 비용 (w > 1) 로 설정한 모델`을 비용민감 모델이라 한다.\n",
    "    - w = 1 이면 일반 모델과 다를 것이 없음.\n",
    "    - w < 1 이면 다수 클래스에 더 초점을 두는 모델이 되버림 (불균형 해소 목적과 맞지 않음)<br><br>\n",
    "- w값의 조절을 통해 소수 클래스에 중점을 얼마나 둘지 설정할 수 있다.\n",
    "    - 아래 그림과 같이 비용 민감 모델은 w값이 커질수록 긍정 클래스로 분류하고자 할 것이다. (재현율 상승, 정확도 하락)\n",
    "![](이미지57.png)\n",
    "\n",
    "\n",
    "- w가 0일때는 정확도가 높은 편이다. (부정 클래스샘플이 대부분일때, 전부 부정클래스로 판단해도 성능이 나빠지지 않는다.)\n",
    "- w가 0일때는 모든 샘플을 부정 클래스로 분류해서 재현율이 0이 된다. \n",
    "- 단, 재현율은 1이 될 수 있지만, 정확도는 0이 되지 않는다.\n",
    "    - w가 커질 수록 대부분의 샘플을 긍정 클래스로 분류하겠지만, 실제 긍정인 비율이 있기 때문에 0이 될 수 없다.\n",
    "---\n",
    "- `위양성 비용 (False positive : TP)` : `부정` 클래스 샘플을 `긍정` 클래스 라고 잘못 분류해서 발생하는 비용<br><br>\n",
    "- `위음성 비용 (False negative : TN)` : `긍정` 클래스 샘플을 `부정` 클래스 라고 잘못 분류해서 발생하는 비용<br><br>\n",
    "---\n",
    "\n",
    "- 기본적으로 모델을 생성하면 위음성 비용과 위양성비용을 같다는 전제하에 작동한다.\n",
    "- 하지만, 실제로는 위음성 비용 > 위양성 비용 (feat. 암환자의 생명 > 정상인의 금전적 비용과 시간)\n",
    "---\n",
    "- 엄밀히 말해서 전처리 함수는 아니다.\n",
    "- 하지만 클래스 불균형 문제 해결에 많이 쓰이는 모델 기법이다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 확률 모델\n",
    "---\n",
    "- Logistic Regression, Naive bayes regression 등의 확률 모델들은 cut-off value(c)를 조정하는 방식으로 비용민감 모델을 구현한다.\n",
    "\n",
    "![](이미지58.png)\n",
    "\n",
    "---\n",
    "- 보통 c(cut-off value)를 0.5로 설정한다. \n",
    "- x가 주어졌을때 y가 1일 확률이 50%이상(c)이면 Positive(1) / y가 1일 확률이 50%이하(c)이면 Negative(-1)로 판단한다.\n",
    "- 이때, c값은 조정이 가능하다. \n",
    "    - c값을 작게 줄 수록 Positive(긍정) 이라 분류하는 경우가 더 많아진다. (= 긍정 클래스의 결정 공간이 넓어진다.)\n",
    "\n",
    "- 결론적으로, c값을 0.5보다 작게 설정하는 것을 확률모델의 비용민감 모델이라 한다.\n",
    "    - c값이 작을 수록 재현율이 높고, 정확도가 낮다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 관련 문법 : .predict_proba\n",
    "---\n",
    "- sklearn의 확률 모델이 갖는 메서드로, X를 입력받아 `각 클래스에 속할 확률을 출력`해준다.\n",
    "- 이전의 다른 전처리법 처럼 모델에 학습시키는 것이 아닌, 학습된 모델에서 활용하는 방식\n",
    "- 모델에 값을 fit한 후에, predict_proba(X)를 사용하면, x에 포함된 모든 값들을 대상으로 Pos 와 Neg에 속할 확률을 출력해준다.\n",
    "---\n",
    "\n",
    "![](이미지59.png)\n",
    "\n",
    "---\n",
    "- Model.classes_=[Neg, Pos] 를 통해 모델학습에 사용된 클래스값을 알수 있다.\n",
    "- 이 결과를 .predict_proba(X) 의 출력결과의 컬럼값으로 활용한다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드 및 클래스 불균형 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T09:06:44.936908Z",
     "start_time": "2021-07-18T09:06:44.024705Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 불필요한 경고 표시 생략\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "a=%pwd # 현재 경로 a에 할당\n",
    "os.chdir(a) # 파일 로드 경로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반도체 공정의 센서값 데이터 (실습용 불균형 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T09:06:45.191323Z",
     "start_time": "2021-07-18T09:06:44.938902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X582</th>\n",
       "      <th>X583</th>\n",
       "      <th>X584</th>\n",
       "      <th>X585</th>\n",
       "      <th>X586</th>\n",
       "      <th>X587</th>\n",
       "      <th>X588</th>\n",
       "      <th>X589</th>\n",
       "      <th>X590</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>97.934373</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>0.021458</td>\n",
       "      <td>0.016475</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>99.670066</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>208.204500</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>208.204500</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>82.860200</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>82.860200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>73.843200</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>73.843200</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>97.934373</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>73.843200</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 591 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1       X2         X3         X4      X5   X6        X7      X8  \\\n",
       "0  3030.93  2564.00  2187.7333  1411.1265  1.3602  100   97.6133  0.1242   \n",
       "1  3095.78  2465.14  2230.4222  1463.6606  0.8294  100  102.3433  0.1247   \n",
       "2  2932.61  2559.94  2186.4111  1698.0172  1.5102  100   95.4878  0.1241   \n",
       "3  2988.72  2479.90  2199.0333   909.7926  1.3204  100  104.2367  0.1217   \n",
       "4  3032.24  2502.87  2233.3667  1326.5200  1.5334  100  100.3967  0.1235   \n",
       "\n",
       "       X9     X10  ...        X582    X583    X584    X585     X586      X587  \\\n",
       "0  1.5005  0.0162  ...   97.934373  0.5005  0.0118  0.0035   2.3630  0.021458   \n",
       "1  1.4966 -0.0005  ...  208.204500  0.5019  0.0223  0.0055   4.4447  0.009600   \n",
       "2  1.4436  0.0041  ...   82.860200  0.4958  0.0157  0.0039   3.1745  0.058400   \n",
       "3  1.4882 -0.0124  ...   73.843200  0.4990  0.0103  0.0025   2.0544  0.020200   \n",
       "4  1.5031 -0.0031  ...   97.934373  0.4800  0.4766  0.1045  99.3032  0.020200   \n",
       "\n",
       "       X588      X589        X590  Y  \n",
       "0  0.016475  0.005283   99.670066 -1  \n",
       "1  0.020100  0.006000  208.204500 -1  \n",
       "2  0.048400  0.014800   82.860200  1  \n",
       "3  0.014900  0.004400   73.843200 -1  \n",
       "4  0.014900  0.004400   73.843200 -1  \n",
       "\n",
       "[5 rows x 591 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Secom.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T09:06:45.206283Z",
     "start_time": "2021-07-18T09:06:45.193318Z"
    }
   },
   "outputs": [],
   "source": [
    "# 특징과 라벨 분리\n",
    "X = df.drop('Y', axis = 1)\n",
    "Y = df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T09:06:47.007147Z",
     "start_time": "2021-07-18T09:06:45.208279Z"
    }
   },
   "outputs": [],
   "source": [
    "# 학습 데이터와 평가 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T09:06:47.022136Z",
     "start_time": "2021-07-18T09:06:47.008144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1175, 590)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특징이 매우 많음(590개)\n",
    "Train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T09:06:47.037072Z",
     "start_time": "2021-07-18T09:06:47.024102Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1094\n",
       " 1      81\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 불균형 확인\n",
    "# 불량이 1094개 / 정상이 81개\n",
    "# class 1의 샘플이 너무 적어, 언더샘플링을 적용하기에는 부적절 \n",
    "Train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T09:06:47.053025Z",
     "start_time": "2021-07-18T09:06:47.040060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.506172839506172"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 불균형 비율 계산\n",
    "Train_Y.value_counts().iloc[0] / Train_Y.value_counts().iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T09:06:47.337491Z",
     "start_time": "2021-07-18T09:06:47.055019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.9413265306122449\n"
     ]
    }
   ],
   "source": [
    "# kNN을 사용한 클래스 불균형 테스트\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# 모델 생성\n",
    "kNN_model = KNN(n_neighbors = 11).fit(Train_X, Train_Y)\n",
    "\n",
    "# 예측\n",
    "pred_Y = kNN_model.predict(Test_X)\n",
    "\n",
    "# 재현율 출력\n",
    "print(recall_score(Test_Y, pred_Y))\n",
    "\n",
    "# 정확도 출력\n",
    "print(accuracy_score(Test_Y, pred_Y))\n",
    "\n",
    "# 정확도는 90%이상이지만, 재현율이 0%로 불균형이 심각한 수준이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비용 민감 모델\n",
    "---\n",
    "- Logistic Regression모델로 테스트 하는 이유<br><br>\n",
    "    - 모델이 가볍고 간단한 구조이다.\n",
    "    - 따라서 max_iter을 크게 잡아도 빠른 시간안에 결론이 도출되고, 과적합에 걸릴 가능성도 매우 낮다.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T09:06:54.892283Z",
     "start_time": "2021-07-18T09:06:47.338488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21739130434782608\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "# 비용 민감 모델 적용전 Logistic Regression 모델로 테스트\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "# 모델 인스턴스 생성 & fitting\n",
    "model = LR(max_iter = 100000).fit(Train_X, Train_Y)\n",
    "\n",
    "# 예측\n",
    "pred_Y = model.predict(Test_X)\n",
    "\n",
    "# 재현율 & 정확도 출력\n",
    "print(recall_score(Test_Y, pred_Y))\n",
    "print(accuracy_score(Test_Y, pred_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 동일한 데이터 셋으로 KNN을 통해 클래스 불균형 탐색을 했을때는 재현율이 0%였던 것에 비해 로지스틱은 KNN대비 높은 재현율값을 보인다. \n",
    "    - 20%대의 재현율이 높은 것은 아니다. (상대적으로 높은 것)\n",
    "- 즉, KNN모델이 클래스 불균형에 매우 민감한 모델인 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cut-off value 조정\n",
    "---\n",
    "- 확률 모델의 cut_off_value 조절하기\n",
    "- Numpy와 Pandas의 유니버셜 함수, 브로드캐스팅, 마스크 연산을 통해 배열 단위 연산을 하는 것이 포인트\n",
    "\n",
    "![](이미지60.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T09:06:54.922203Z",
     "start_time": "2021-07-18T09:06:54.893281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.391304347826087\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "# 위에서 생성한 LR모델에 predict_proba() 함수를 사용해 해당 모델을 통해 Test_X의 샘플이 각 클래스에 속할 확률을 출력\n",
    "probs = model.predict_proba(Test_X)\n",
    "\n",
    "# 결과를 DataFrame으로 변경\n",
    "# model.classes_ 는 fitting이 된 이후에만 사용 가능 (어떤 클래스를 바탕으로 학습된 것인지를 저장하는 함수)\n",
    "probs = pd.DataFrame(probs, columns = model.classes_)\n",
    "\n",
    "# cut-off value 비율 설정\n",
    "cut_off_value = 0.3\n",
    "\n",
    "pred_Y = 2 * (probs.iloc[:, -1] >= cut_off_value) - 1\n",
    "print(recall_score(Test_Y, pred_Y))\n",
    "print(accuracy_score(Test_Y, pred_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 재현율은 거의 40%가까이 증가한 반면, 정확도는 동일하다.\n",
    "- 이 경우는 c값의 조절이 어느정도 잘 이뤄진 결과 이다.\n",
    "- 하지만 위와 같이 처음 정한 c값이 좋은 결과를 내지 못할 수도 있고, 매번 수치를 입력해가면서 결과를 확인하는 것은 비효율 적이다.\n",
    "- 따라서 함수를 활용해 cut-off value를 조정하는 결과를 시각화 하는 방법을 아래에 정리하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cut-off value를 변화하여 비용 민감 모델 성능 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T09:06:54.937163Z",
     "start_time": "2021-07-18T09:06:54.923201Z"
    }
   },
   "outputs": [],
   "source": [
    "# cut off value를 조정하는 함수 작성\n",
    "def cost_sensitive_model(model, cut_off_value, Test_X, Test_Y):\n",
    "    \n",
    "    # predict_proba 로 클래스별 확률 출력\n",
    "    probs = model.predict_proba(Test_X)\n",
    "    \n",
    "    # 결과값을 DataFrame으로 변경\n",
    "    probs = pd.DataFrame(probs, columns = model.classes_)\n",
    "    \n",
    "    # cut-off value에 따른 예측값\n",
    "    pred_Y = 2 * (probs.iloc[:, -1] >= cut_off_value) - 1\n",
    "    \n",
    "    # 재현율 * 정확도 계산\n",
    "    recall = recall_score(Test_Y, pred_Y)\n",
    "    accuracy = accuracy_score(Test_Y, pred_Y)\n",
    "    \n",
    "    # 출력\n",
    "    return recall, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 과정을 하나의 함수로 만들어서 cut-off value 변화에 따른 결과를 간편하게 살펴보면서, 최적의 값을 찾도록 할 수 있다.\n",
    "- 기존의 다른 전처리법은 모델을 학습한 이후에 조정을 하고, 다시 모델에 학습시키는 과정을 반복한다.\n",
    "- 하지만 cut-off value의 경우 이미 학습된 모델이 있고, c값만 조정하기 때문에 작업 과정에 시간이 많이 소비되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cut off value에 따른 recall과 accuracy 변화를 시각화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T09:08:00.497132Z",
     "start_time": "2021-07-18T09:07:59.422009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21f29452850>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from shapely.geometry import LineString\n",
    "import numpy as np\n",
    "\n",
    "# x축\n",
    "cut_off_value_list = np.linspace(0, 1, 101) # 0부터 1까지 총 101개의 값을 list로 입력\n",
    "\n",
    "# y축 (재현율 & 정확도)\n",
    "recall_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "# 생성한 cost_sensitive_model 모델로 x축값에 따른 y축의 값 출력\n",
    "for c in cut_off_value_list:\n",
    "    recall, accuracy = cost_sensitive_model(model, c, Test_X, Test_Y)\n",
    "    recall_list.append(recall)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "# 결과 시각화\n",
    "%matplotlib inline    \n",
    "plt.plot(cut_off_value_list, recall_list, label = 'recall')   \n",
    "plt.plot(cut_off_value_list, accuracy_list, label = 'accuracy')    \n",
    "\n",
    "# 교차점 찾기\n",
    "line_1 = LineString(np.column_stack((cut_off_value_list, recall_list)))\n",
    "line_2 = LineString(np.column_stack((cut_off_value_list, accuracy_list)))\n",
    "intersection = line_1.intersection(line_2)\n",
    "\n",
    "plt.plot(*intersection.xy,'ro')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과값을 보고 재현율과 정확도를 보면서 분석가가 원하는 수준의 값을 지정해야 한다. (주관적 판단)\n",
    "- 가장 무난한 수치는 두 그래프가 교차하는 지점을 선택하는 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_env]",
   "language": "python",
   "name": "conda-env-my_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
